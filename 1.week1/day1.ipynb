{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display, Markdown\n",
    "from openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key found in .env file.\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    print(\"OpenAI API key found in .env file.\")\n",
    "else:\n",
    "    print(\"OpenAI API key not found in .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai=OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First call to GPT LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm glad you're here. While I can't send messages to the future, I'm here to help you with anything you need now. What would you like to discuss or explore today?\n"
     ]
    }
   ],
   "source": [
    "# It's a preview first call to check if the API key is working or not\n",
    "user_prompt=\"Hello, GPT! Send my first message to you in 2025! I just started\"\n",
    "response=openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": user_prompt}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First project - Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response=requests.get(url, headers=headers)\n",
    "        soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "        self.title=soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\",\"img\",\"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text=soup.body.get_text(separator=\"\\n\", strip=True)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Football News, Live Scores, Results & Transfers | Goal.com\n",
      "SCORES\n",
      "LATEST\n",
      "Football News\n",
      "News\n",
      "Transfers\n",
      "Opinion\n",
      "Analysis\n",
      "Player Ratings\n",
      "Winners & Losers\n",
      "Power Rankings\n",
      "Entertainment\n",
      "Culture\n",
      "Kits\n",
      "Boots\n",
      "Tickets\n",
      "Buyers' guides\n",
      "Gaming\n",
      "Quizzes\n",
      "Social\n",
      "Facebook\n",
      "X\n",
      "Instagram\n",
      "TikTok\n",
      "YouTube\n",
      "COMPETITIONS\n",
      "Leagues\n",
      "Premier League\n",
      "La Liga\n",
      "Serie A\n",
      "Bundesliga\n",
      "Ligue 1\n",
      "UEFA Champions League\n",
      "UEFA Europa League\n",
      "UEFA Europa Conference League\n",
      "MLS\n",
      "Saudi Pro League\n",
      "Clubs\n",
      "Manchester United\n",
      "Liverpool\n",
      "Manchester City\n",
      "Chelsea\n",
      "Arsenal\n",
      "Real Madrid\n",
      "Barcelona\n",
      "PSG\n",
      "Bayern Munich\n",
      "Juventus\n",
      "Inter Miami\n",
      "Al-Nassr\n",
      "International\n",
      "England\n",
      "Argentina\n",
      "Brazil\n",
      "France\n",
      "USMNT\n",
      "Germany\n",
      "Spain\n",
      "Italy\n",
      "Portugal\n",
      "Netherlands\n",
      "Belgium\n",
      "Women's Football\n",
      "Latest News\n",
      "UWCL\n",
      "WSL\n",
      "NWSL\n",
      "Players\n",
      "Cristiano Ronaldo\n",
      "Lionel Messi\n",
      "Kylian Mbappe\n",
      "Erling Haaland\n",
      "Neymar\n",
      "INDIVISA\n",
      "MUNDIAL\n",
      "GOALSTUDIO\n",
      "Matches\n",
      "All competitions\n",
      "Premier League\n",
      "Serie A\n",
      "Bundesliga\n",
      "LaLiga\n",
      "Ligue 1\n",
      "WSL\n",
      "Championship\n",
      "All competitions\n",
      "Tue 17 Dec\n",
      "Wed 18 Dec\n",
      "Thu 19 Dec\n",
      "Fri 20 Dec\n",
      "Sat 21 Dec\n",
      "Sun 22 Dec\n",
      "Mon 23 Dec\n",
      "Tue 24 Dec\n",
      "Wed 25 Dec\n",
      "Thu 26 Dec\n",
      "Fri 27 Dec\n",
      "Sat 28 Dec\n",
      "Sun 29 Dec\n",
      "Mon 30 Dec\n",
      "Yesterday\n",
      "Today\n",
      "Tomorrow\n",
      "Fri 3 Jan\n",
      "Sat 4 Jan\n",
      "Sun 5 Jan\n",
      "Mon 6 Jan\n",
      "Tue 7 Jan\n",
      "Wed 8 Jan\n",
      "Thu 9 Jan\n",
      "Fri 10 Jan\n",
      "Sat 11 Jan\n",
      "Sun 12 Jan\n",
      "Mon 13 Jan\n",
      "Tue 14 Jan\n",
      "Wed 15 Jan\n",
      "Thu 16 Jan\n",
      "Championship\n",
      "19:30\n",
      "PLY\n",
      "PLY\n",
      "BRC\n",
      "BRC\n",
      "-\n",
      "-\n",
      "Championship\n",
      "19:30\n",
      "QPR\n",
      "QPR\n",
      "WAT\n",
      "WAT\n",
      "-\n",
      "-\n",
      "Championship\n",
      "20:00\n",
      "MIL\n",
      "MIL\n",
      "OXF\n",
      "OXF\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "CAC\n",
      "CAC\n",
      "COV\n",
      "COV\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "SHW\n",
      "SHW\n",
      "DER\n",
      "DER\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "LUT\n",
      "LUT\n",
      "NOR\n",
      "NOR\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "POR\n",
      "POR\n",
      "SWA\n",
      "SWA\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "BUR\n",
      "BUR\n",
      "STK\n",
      "STK\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "LEE\n",
      "LEE\n",
      "BLB\n",
      "BLB\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "WBA\n",
      "WBA\n",
      "PNE\n",
      "PNE\n",
      "-\n",
      "-\n",
      "Football's biggest winners & losers of 2024\n",
      "GOAL\n",
      "Opinion\n",
      "Arsenal\n",
      "Rashford gamble & Saka cover in January can keep Arsenal alive\n",
      "Arsenal had hoped this would be the season their title dreams came true, but those hopes are fading fast and swift action is needed in the market\n",
      "Getty Images Sport\n",
      "W. Rooney\n",
      "Plymouth\n",
      "Rooney SACKED by Plymouth after dismal nine-match winless run\n",
      "Plymouth have parted ways with head coach Wayne Rooney, with the club sitting bottom of the Championship.\n",
      "Getty\n",
      "Analysis\n",
      "Real Madrid\n",
      "Signing Trent & loaning Endrick top Real's January to-do list\n",
      "Real Madrid may actually have a lot of work to do when the market opens up in the New Year\n",
      "Getty\n",
      "Player ratings\n",
      "Manchester United\n",
      "Zirkzee & Casemiro atrocious in abysmal Man Utd defeat\n",
      "The Red Devils produced a shambolic first-half display as they sunk to a fourth consecutive defeat in all competitions for the first time in 63 years\n",
      "Getty\n",
      "Chelsea\n",
      "Ipswich vs Chelsea\n",
      "Palmer brilliance unable to rescue Chelsea from shock loss\n",
      "Chelsea failed to bounce back from their recent Fulham defeat and have lost back-to-back Premier League games for the first time under Enzo Maresca.\n",
      "Getty/GOAL\n",
      "Opinion\n",
      "Manchester United\n",
      "Man Utd must sell Rashford & find a goal-scorer in January\n",
      "Here's what the Red Devils should do when the window opens to give Ruben Amorim the best chance of getting the team back on track\n",
      "Getty/GOAL\n",
      "Opinion\n",
      "Chelsea\n",
      "Selling deadwood & replacing Sanchez key to Chelsea's window\n",
      "The Blues will be over the moon with their progress this season, but that doesn't mean there isn't work to be done when the window creaks open\n",
      "Getty Images Sport\n",
      "Transfers\n",
      "Premier League\n",
      "Transfers LIVE: Man Utd flop Antony wanted in shock January swoop\n",
      "GOAL takes a look at the biggest transfer news and rumours from around the world\n",
      "Getty/GOAL\n",
      "Opinion\n",
      "Barcelona\n",
      "Free agents & Fati future among Barca's January priorities\n",
      "The Blaugrana are unlikely to have any money to spend on new signings, but Joan Laporta & Co. will still be very busy over the next month...\n",
      "BREAKING NEWS\n",
      "Bundesliga top scorers 2024: Who is leading the race?\n",
      "Amorim sends message to Man Utd supporters heading into 2025\n",
      "'Like a hammer' - Arteta tells Arsenal how to hunt down Liverpool\n",
      "Bold predictions for 2025: Chelsea win CWC, Neymar to MLS\n",
      "Bring on 2025: New Year's resolutions for U.S. national teams\n",
      "Barcelona and La Liga release conflicting Olmo statements\n",
      "'Grateful for being alive!' - Antonio breaks silence after car crash\n",
      "'Good luck' - Frank's warning to Mbeumo suitors for January\n",
      "Newcastle's revolution could be over! Trippier to be sold in January\n",
      "Williams and Isak headline Arsenal shortlist\n",
      "Could Spurs cancel Werner's loan?\n",
      "Carragher slams TAA and his agents for Real Madrid reports\n",
      "Rooney could receive immediate offer after Plymouth sacking\n",
      "Topless Dalot sports futuristic glasses during bizarre laser procedure\n",
      "'Lock the door behind him!' - TAA should be 'kept in the basement'\n",
      "BREAKING NEWS\n",
      "Advertisement\n",
      "Must-read opinion and expert analysis\n",
      "Doping suspension spells the end for Mudryk at Chelsea\n",
      "Top 10 Premier League signings of the season so far - ranked\n",
      "Saka has been FAILED! Arsenal didn't protect their 'Starboy'\n",
      "Europe, Saudi or MLS? Rashford's potential destinations - ranked\n",
      "The best players, coaches & teams of the 21st century - ranked\n",
      "Doping suspension spells the end for Mudryk at Chelsea\n",
      "Culture and fashion\n",
      "Can UFL take EAFC's crown? CR7-backed game making a splash\n",
      "Culture & Clobber Axis: Yamal's new boots, Rashford & more\n",
      "The Culture & Clobber Axis: Palmer's Panenka & Arsenal x adidas\n",
      "Inside Under Armour's bid to make defending cool again\n",
      "PUMA's secret to creating iconic AFCON kits\n",
      "How trendsetter Beckham remains football's king of fashion\n",
      "This is the Premier League\n",
      "(C)Getty Images\n",
      "R. Amorim\n",
      "Manchester United\n",
      "Amorim sends message to Man Utd supporters heading into 2025\n",
      "Ruben Amorim sent a message to Manchester United supporters heading into 2025 after suffering four straight losses.\n",
      "Getty Images Sport\n",
      "Arsenal\n",
      "M. Arteta\n",
      "'Like a hammer' - Arteta tells Arsenal how to hunt down Liverpool\n",
      "Mikel Arteta wants his Arsenal players to be as persistent as a \"hammer\" to hunt down Premier League leaders Liverpool.\n",
      "AFP\n",
      "M. Antonio\n",
      "West Ham\n",
      "'Grateful for being alive!' - Antonio breaks silence after car crash\n",
      "Michail Antonio sent an emotional message to West Ham fans after a horror car crash left him hospitalised with a broken leg.\n",
      "Brentford\n",
      "B. Mbeumo\n",
      "'Good luck' - Frank's warning to Mbeumo suitors for January\n",
      "Thomas Frank has warned Bryan Mbeumo's suitors that they have next to no chance of signing the Brentford striker in January.\n",
      "More\n",
      "Transfer news and done deals ü§ù\n",
      "Barcelona\n",
      "D. Olmo\n",
      "Barcelona and La Liga release conflicting Olmo statements\n",
      "Barcelona and La Liga have released conflicting statements surrounding the future of attacking midfielder Dani Olmo.\n",
      "Getty Images Sport\n",
      "K. Trippier\n",
      "Newcastle\n",
      "Newcastle's revolution could be over! Trippier to be sold in January\n",
      "Newcastle United could sell Kieran Trippier with a January move abroad on the cards, three years after he first joined the club.\n",
      "Getty/GOAL\n",
      "Arsenal\n",
      "Premier League\n",
      "Williams and Isak headline Arsenal shortlist\n",
      "Nico Williams and Alexander Isak are both under consideration as Arsenal aim to sign a wide forward in January, per a new report.\n",
      "Getty Images Sport\n",
      "T. Werner\n",
      "Tottenham\n",
      "Could Spurs cancel Werner's loan?\n",
      "Tottenham could cancel Timo Werner's loan but RB Leipzig are reportedly reluctant to take him back due to his wages amid a poor run of form.\n",
      "More\n",
      "Video\n",
      "CULTURE\n",
      "Gaming\n",
      "WATCH: Front Three End of Year awards for 2024!\n",
      "Front Three awards 2024 edition is here! DSK, Yani, Ali, Jules and Juwon definitely won't want to win some of these accolades...\n",
      "GOAL\n",
      "CULTURE\n",
      "Gaming\n",
      "WATCH: Pure chaos! Front Three play football Trivia Pursuit\n",
      "Front Three content creators Jules and Yani play the new football Trivia Pursuit format to show off their endless ball knowledge skills\n",
      "GOAL\n",
      "CULTURE\n",
      "Gaming\n",
      "WATCH: Front Three play The Chase - Real Madrid edition\n",
      "Front Three football content creators face Real Madrid's biggest fan, Jules, and play the most epic football quiz\n",
      "GOAL\n",
      "CULTURE\n",
      "Gaming\n",
      "No Messi or CR7! Front Three crown the greatest striker of this generation\n",
      "Front Three content creators Yarns, Juwon, DSK and Ali put together a football strikers tier list and rank the best of this generation\n",
      "GOAL\n",
      "C. Ronaldo\n",
      "Saudi Pro League\n",
      "WATCH: DSK gets a wink from Cristiano as Front Three plays football bingo!\n",
      "Front Three football content creators DSK, Yarns, Juwon and Ali travelled to Saudi Arabia on a quest to meet Al-Nassr star Cristiano Ronaldo!\n",
      "More\n",
      "Queens of football üëë\n",
      "FEATURES\n",
      "NWSL\n",
      "Grading Bethune, Spirit and the 2024 NWSL rookie class\n",
      "INDIVISA grades the 2024 NWSL rookie class after a monumental season for the league\n",
      "AFP\n",
      "J. Lingard\n",
      "Manchester United Women\n",
      "Lingard back at Man Utd?! FC Seoul man trains with cousin George\n",
      "Former Manchester United man Jesse Lingard was back in familiar surroundings as he appeared to train with Gabby George during his off-season break.\n",
      "Getty Images, Sky Sports\n",
      "L. Williamson\n",
      "Arsenal Women\n",
      "Williamson reveals darts nickname and walk-on song for alternate career\n",
      "Arsenal and England defender Leah Williamson reimagined her career as a darts player after trip to 2025 World Championship at Alexandra Palace.\n",
      "GOAL\n",
      "E. Hayes\n",
      "S. Bompastor\n",
      "Hayes says it was 'the right time' to leave Chelsea\n",
      "Former Chelsea boss Emma Hayes has claimed that it was 'the right time' to leave the Blues as she opens up on Sonia Bompastor's perfect start.\n",
      "Getty Images Sport\n",
      "NJ/NY Gotham FC\n",
      "Houston Dash\n",
      "Gotham trade USWNT attacker Ryan to Houston Dash\n",
      "The Bats honored Ryan's request to be traded, with the 25-year-old on the move to Houston\n",
      "More\n",
      "Superstars of the future\n",
      "Getty/GOAL\n",
      "Monaco\n",
      "E. Ben Seghir\n",
      "Why Monaco's teenage 'prince' is on Barca's radar\n",
      "The fleet-footed teenager has been lighting up Stade Louis II in the 2024-25 campaign, and could be in line for a dream move if he can keep it up\n",
      "Getty/GOAL\n",
      "Manchester City\n",
      "Premier League\n",
      "EPL legend's son emerging as City's academy goal machine\n",
      "The tricky winger has scored for the Cityzens at every age group level and all that is left is to make his senior debut alongside his older brother\n",
      "GOAL\n",
      "Chelsea\n",
      "Analysis\n",
      "Why Europe's elite want Chelsea contract rebel Acheampong\n",
      "The versatile defender could be the next jewel of the club's esteemed Cobham academy, but they have a fight on their hands to keep him\n",
      "Getty/GOAL\n",
      "Arsenal\n",
      "Premier League\n",
      "Arsenal's 14-year-old phenom already earning Arteta's trust\n",
      "A midfielder with typical Gunners flair, the schoolboy is set to become the latest talent to come out of the club's Hale End academy\n",
      "More\n",
      "The Chaaaaaampions üé∂\n",
      "Getty Images Sport\n",
      "Manchester United\n",
      "Premier League\n",
      "Man Utd live stream and TV channel broadcast info\n",
      "Everything you need to know about how to watch Man Utd in the Premier League and all major competitions.\n",
      "Getty/GOAL\n",
      "Vinicius Junior\n",
      "K. Mbappe\n",
      "Vinicius warned he could be sold as Mbappe is Real's 'darling'\n",
      "Former Real Madrid scout Manolo Romero has warned Vinicius Junior that Florentino Perez would sell him as he prefers Kylian Mbappe over the Brazilian.\n",
      "Getty/GOAL\n",
      "C. Ronaldo\n",
      "Manchester City\n",
      "Ronaldo gives advice to Man City players amid disastrous form\n",
      "Cristiano Ronaldo had a bit of advice for Manchester City players as he backed Pep Guardiola's side to \"come back\" from their miserable run.\n",
      "Getty/GOAL\n",
      "Arsenal\n",
      "B. Saka\n",
      "Carragher explains what Arsenal need to win Premier League title\n",
      "Jamie Carragher has explained how Mikel Arteta can lead Arsenal to the Premier League title while claiming they depend too much on Bukayo Saka.\n",
      "More\n"
     ]
    }
   ],
   "source": [
    "# Let's test and print the results\n",
    "goal=Website(\"https://www.goal.com/en\")\n",
    "print(goal.title)\n",
    "print(goal.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning.AI: Start or Advance Your Career in AI\n",
      "‚ú® New course! Enroll in\n",
      "Reasoning with o1\n",
      "Explore Courses\n",
      "AI Newsletter\n",
      "The Batch\n",
      "Andrew's Letter\n",
      "Data Points\n",
      "ML Research\n",
      "Blog\n",
      "Community\n",
      "Forum\n",
      "Events\n",
      "Ambassadors\n",
      "Ambassador Spotlight\n",
      "Resources\n",
      "Company\n",
      "About\n",
      "Careers\n",
      "Contact\n",
      "Start Learning\n",
      "AI is the new electricity.\n",
      "You are the spark.\n",
      "Get the latest AI news, courses, events, and insights from Andrew Ng and other AI leaders.\n",
      "Subscribe\n",
      "First Name\n",
      "Last Name\n",
      "Where do you live?\n",
      "Select a country\n",
      "What is your job title?\n",
      "Please select\n",
      "Keep me updated on the latest news, events, and courses\n",
      "Subscribe\n",
      "Join over 7 million people learning how to use and build AI\n",
      "AI Courses and Specializations\n",
      "Build a foundation of machine learning and AI skills, and understand how to apply them in the real world.\n",
      "Explore All Courses\n",
      "In Collaboration With\n",
      "prev\n",
      "next\n",
      "The largest weekly AI newsletter\n",
      "What matters in AI right now\n",
      "Dec 25, 2024\n",
      "Top AI Stories of 2024! Agents Rise, Prices Fall, Models Shrink, Video Takes Off, Acquisitions Morph\n",
      "The Batch AI News and Insights: Is AI progressing rapidly? Yes! But while the progress of underlying AI technology has indeed sped up over the past 2 years, the fastest acceleration is in applications.\n",
      "Dec 18, 2024\n",
      "Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, Gemini 2.0 Flash Accelerates Multimodal Modeling, LLMs Propose Research Ideas\n",
      "The Batch AI News and Insights: I‚Äôm thrilled that former students and postdocs of mine¬†won¬†both of this year‚Äôs NeurIPS Test of Time Paper Awards.\n",
      "Dec 11, 2024\n",
      "Amazon Nova‚Äôs Competitive Price/Performance, OpenAI o1 Pro‚Äôs High Price/Performance, Google‚Äôs Game Worlds on Tap, Factual LLMs\n",
      "The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications.\n",
      "Read more\n",
      "Free Resources\n",
      "Get Started with AI and Machine Learning\n",
      "How to Build Your Career in AI\n",
      "A practical roadmap to building your career in AI from AI pioneer Andrew Ng\n",
      "Download\n",
      "Machine Learning Yearning\n",
      "An introductory book about developing ML algorithms.\n",
      "Download\n",
      "A Complete Guide to Natural Language Processing\n",
      "A comprehensive guide covering all you need to know about NLP.\n",
      "Read more\n",
      "Stay up to date on the latest news, courses, and AI events\n",
      "Subscribe\n",
      "First Name\n",
      "Last Name\n",
      "Where do you live?\n",
      "Select a country\n",
      "What is your job title?\n",
      "Please select\n",
      "Keep me updated on the latest news, events, and courses\n",
      "Subscribe\n",
      "Courses\n",
      "The Batch\n",
      "Community\n",
      "Careers\n",
      "About\n"
     ]
    }
   ],
   "source": [
    "dl=Website(\"https://www.deeplearning.ai\")\n",
    "print(dl.title)\n",
    "print(dl.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled Football News, Live Scores, Results & Transfers | Goal.com\n",
      "The contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\n",
      "\n",
      "SCORES\n",
      "LATEST\n",
      "Football News\n",
      "News\n",
      "Transfers\n",
      "Opinion\n",
      "Analysis\n",
      "Player Ratings\n",
      "Winners & Losers\n",
      "Power Rankings\n",
      "Entertainment\n",
      "Culture\n",
      "Kits\n",
      "Boots\n",
      "Tickets\n",
      "Buyers' guides\n",
      "Gaming\n",
      "Quizzes\n",
      "Social\n",
      "Facebook\n",
      "X\n",
      "Instagram\n",
      "TikTok\n",
      "YouTube\n",
      "COMPETITIONS\n",
      "Leagues\n",
      "Premier League\n",
      "La Liga\n",
      "Serie A\n",
      "Bundesliga\n",
      "Ligue 1\n",
      "UEFA Champions League\n",
      "UEFA Europa League\n",
      "UEFA Europa Conference League\n",
      "MLS\n",
      "Saudi Pro League\n",
      "Clubs\n",
      "Manchester United\n",
      "Liverpool\n",
      "Manchester City\n",
      "Chelsea\n",
      "Arsenal\n",
      "Real Madrid\n",
      "Barcelona\n",
      "PSG\n",
      "Bayern Munich\n",
      "Juventus\n",
      "Inter Miami\n",
      "Al-Nassr\n",
      "International\n",
      "England\n",
      "Argentina\n",
      "Brazil\n",
      "France\n",
      "USMNT\n",
      "Germany\n",
      "Spain\n",
      "Italy\n",
      "Portugal\n",
      "Netherlands\n",
      "Belgium\n",
      "Women's Football\n",
      "Latest News\n",
      "UWCL\n",
      "WSL\n",
      "NWSL\n",
      "Players\n",
      "Cristiano Ronaldo\n",
      "Lionel Messi\n",
      "Kylian Mbappe\n",
      "Erling Haaland\n",
      "Neymar\n",
      "INDIVISA\n",
      "MUNDIAL\n",
      "GOALSTUDIO\n",
      "Matches\n",
      "All competitions\n",
      "Premier League\n",
      "Serie A\n",
      "Bundesliga\n",
      "LaLiga\n",
      "Ligue 1\n",
      "WSL\n",
      "Championship\n",
      "All competitions\n",
      "Tue 17 Dec\n",
      "Wed 18 Dec\n",
      "Thu 19 Dec\n",
      "Fri 20 Dec\n",
      "Sat 21 Dec\n",
      "Sun 22 Dec\n",
      "Mon 23 Dec\n",
      "Tue 24 Dec\n",
      "Wed 25 Dec\n",
      "Thu 26 Dec\n",
      "Fri 27 Dec\n",
      "Sat 28 Dec\n",
      "Sun 29 Dec\n",
      "Mon 30 Dec\n",
      "Yesterday\n",
      "Today\n",
      "Tomorrow\n",
      "Fri 3 Jan\n",
      "Sat 4 Jan\n",
      "Sun 5 Jan\n",
      "Mon 6 Jan\n",
      "Tue 7 Jan\n",
      "Wed 8 Jan\n",
      "Thu 9 Jan\n",
      "Fri 10 Jan\n",
      "Sat 11 Jan\n",
      "Sun 12 Jan\n",
      "Mon 13 Jan\n",
      "Tue 14 Jan\n",
      "Wed 15 Jan\n",
      "Thu 16 Jan\n",
      "Championship\n",
      "19:30\n",
      "PLY\n",
      "PLY\n",
      "BRC\n",
      "BRC\n",
      "-\n",
      "-\n",
      "Championship\n",
      "19:30\n",
      "QPR\n",
      "QPR\n",
      "WAT\n",
      "WAT\n",
      "-\n",
      "-\n",
      "Championship\n",
      "20:00\n",
      "MIL\n",
      "MIL\n",
      "OXF\n",
      "OXF\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "CAC\n",
      "CAC\n",
      "COV\n",
      "COV\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "SHW\n",
      "SHW\n",
      "DER\n",
      "DER\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "LUT\n",
      "LUT\n",
      "NOR\n",
      "NOR\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "POR\n",
      "POR\n",
      "SWA\n",
      "SWA\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "BUR\n",
      "BUR\n",
      "STK\n",
      "STK\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "LEE\n",
      "LEE\n",
      "BLB\n",
      "BLB\n",
      "-\n",
      "-\n",
      "Championship\n",
      "22:00\n",
      "WBA\n",
      "WBA\n",
      "PNE\n",
      "PNE\n",
      "-\n",
      "-\n",
      "Football's biggest winners & losers of 2024\n",
      "GOAL\n",
      "Opinion\n",
      "Arsenal\n",
      "Rashford gamble & Saka cover in January can keep Arsenal alive\n",
      "Arsenal had hoped this would be the season their title dreams came true, but those hopes are fading fast and swift action is needed in the market\n",
      "Getty Images Sport\n",
      "W. Rooney\n",
      "Plymouth\n",
      "Rooney SACKED by Plymouth after dismal nine-match winless run\n",
      "Plymouth have parted ways with head coach Wayne Rooney, with the club sitting bottom of the Championship.\n",
      "Getty\n",
      "Analysis\n",
      "Real Madrid\n",
      "Signing Trent & loaning Endrick top Real's January to-do list\n",
      "Real Madrid may actually have a lot of work to do when the market opens up in the New Year\n",
      "Getty\n",
      "Player ratings\n",
      "Manchester United\n",
      "Zirkzee & Casemiro atrocious in abysmal Man Utd defeat\n",
      "The Red Devils produced a shambolic first-half display as they sunk to a fourth consecutive defeat in all competitions for the first time in 63 years\n",
      "Getty\n",
      "Chelsea\n",
      "Ipswich vs Chelsea\n",
      "Palmer brilliance unable to rescue Chelsea from shock loss\n",
      "Chelsea failed to bounce back from their recent Fulham defeat and have lost back-to-back Premier League games for the first time under Enzo Maresca.\n",
      "Getty/GOAL\n",
      "Opinion\n",
      "Manchester United\n",
      "Man Utd must sell Rashford & find a goal-scorer in January\n",
      "Here's what the Red Devils should do when the window opens to give Ruben Amorim the best chance of getting the team back on track\n",
      "Getty/GOAL\n",
      "Opinion\n",
      "Chelsea\n",
      "Selling deadwood & replacing Sanchez key to Chelsea's window\n",
      "The Blues will be over the moon with their progress this season, but that doesn't mean there isn't work to be done when the window creaks open\n",
      "Getty Images Sport\n",
      "Transfers\n",
      "Premier League\n",
      "Transfers LIVE: Man Utd flop Antony wanted in shock January swoop\n",
      "GOAL takes a look at the biggest transfer news and rumours from around the world\n",
      "Getty/GOAL\n",
      "Opinion\n",
      "Barcelona\n",
      "Free agents & Fati future among Barca's January priorities\n",
      "The Blaugrana are unlikely to have any money to spend on new signings, but Joan Laporta & Co. will still be very busy over the next month...\n",
      "BREAKING NEWS\n",
      "Bundesliga top scorers 2024: Who is leading the race?\n",
      "Amorim sends message to Man Utd supporters heading into 2025\n",
      "'Like a hammer' - Arteta tells Arsenal how to hunt down Liverpool\n",
      "Bold predictions for 2025: Chelsea win CWC, Neymar to MLS\n",
      "Bring on 2025: New Year's resolutions for U.S. national teams\n",
      "Barcelona and La Liga release conflicting Olmo statements\n",
      "'Grateful for being alive!' - Antonio breaks silence after car crash\n",
      "'Good luck' - Frank's warning to Mbeumo suitors for January\n",
      "Newcastle's revolution could be over! Trippier to be sold in January\n",
      "Williams and Isak headline Arsenal shortlist\n",
      "Could Spurs cancel Werner's loan?\n",
      "Carragher slams TAA and his agents for Real Madrid reports\n",
      "Rooney could receive immediate offer after Plymouth sacking\n",
      "Topless Dalot sports futuristic glasses during bizarre laser procedure\n",
      "'Lock the door behind him!' - TAA should be 'kept in the basement'\n",
      "BREAKING NEWS\n",
      "Advertisement\n",
      "Must-read opinion and expert analysis\n",
      "Doping suspension spells the end for Mudryk at Chelsea\n",
      "Top 10 Premier League signings of the season so far - ranked\n",
      "Saka has been FAILED! Arsenal didn't protect their 'Starboy'\n",
      "Europe, Saudi or MLS? Rashford's potential destinations - ranked\n",
      "The best players, coaches & teams of the 21st century - ranked\n",
      "Doping suspension spells the end for Mudryk at Chelsea\n",
      "Culture and fashion\n",
      "Can UFL take EAFC's crown? CR7-backed game making a splash\n",
      "Culture & Clobber Axis: Yamal's new boots, Rashford & more\n",
      "The Culture & Clobber Axis: Palmer's Panenka & Arsenal x adidas\n",
      "Inside Under Armour's bid to make defending cool again\n",
      "PUMA's secret to creating iconic AFCON kits\n",
      "How trendsetter Beckham remains football's king of fashion\n",
      "This is the Premier League\n",
      "(C)Getty Images\n",
      "R. Amorim\n",
      "Manchester United\n",
      "Amorim sends message to Man Utd supporters heading into 2025\n",
      "Ruben Amorim sent a message to Manchester United supporters heading into 2025 after suffering four straight losses.\n",
      "Getty Images Sport\n",
      "Arsenal\n",
      "M. Arteta\n",
      "'Like a hammer' - Arteta tells Arsenal how to hunt down Liverpool\n",
      "Mikel Arteta wants his Arsenal players to be as persistent as a \"hammer\" to hunt down Premier League leaders Liverpool.\n",
      "AFP\n",
      "M. Antonio\n",
      "West Ham\n",
      "'Grateful for being alive!' - Antonio breaks silence after car crash\n",
      "Michail Antonio sent an emotional message to West Ham fans after a horror car crash left him hospitalised with a broken leg.\n",
      "Brentford\n",
      "B. Mbeumo\n",
      "'Good luck' - Frank's warning to Mbeumo suitors for January\n",
      "Thomas Frank has warned Bryan Mbeumo's suitors that they have next to no chance of signing the Brentford striker in January.\n",
      "More\n",
      "Transfer news and done deals ü§ù\n",
      "Barcelona\n",
      "D. Olmo\n",
      "Barcelona and La Liga release conflicting Olmo statements\n",
      "Barcelona and La Liga have released conflicting statements surrounding the future of attacking midfielder Dani Olmo.\n",
      "Getty Images Sport\n",
      "K. Trippier\n",
      "Newcastle\n",
      "Newcastle's revolution could be over! Trippier to be sold in January\n",
      "Newcastle United could sell Kieran Trippier with a January move abroad on the cards, three years after he first joined the club.\n",
      "Getty/GOAL\n",
      "Arsenal\n",
      "Premier League\n",
      "Williams and Isak headline Arsenal shortlist\n",
      "Nico Williams and Alexander Isak are both under consideration as Arsenal aim to sign a wide forward in January, per a new report.\n",
      "Getty Images Sport\n",
      "T. Werner\n",
      "Tottenham\n",
      "Could Spurs cancel Werner's loan?\n",
      "Tottenham could cancel Timo Werner's loan but RB Leipzig are reportedly reluctant to take him back due to his wages amid a poor run of form.\n",
      "More\n",
      "Video\n",
      "CULTURE\n",
      "Gaming\n",
      "WATCH: Front Three End of Year awards for 2024!\n",
      "Front Three awards 2024 edition is here! DSK, Yani, Ali, Jules and Juwon definitely won't want to win some of these accolades...\n",
      "GOAL\n",
      "CULTURE\n",
      "Gaming\n",
      "WATCH: Pure chaos! Front Three play football Trivia Pursuit\n",
      "Front Three content creators Jules and Yani play the new football Trivia Pursuit format to show off their endless ball knowledge skills\n",
      "GOAL\n",
      "CULTURE\n",
      "Gaming\n",
      "WATCH: Front Three play The Chase - Real Madrid edition\n",
      "Front Three football content creators face Real Madrid's biggest fan, Jules, and play the most epic football quiz\n",
      "GOAL\n",
      "CULTURE\n",
      "Gaming\n",
      "No Messi or CR7! Front Three crown the greatest striker of this generation\n",
      "Front Three content creators Yarns, Juwon, DSK and Ali put together a football strikers tier list and rank the best of this generation\n",
      "GOAL\n",
      "C. Ronaldo\n",
      "Saudi Pro League\n",
      "WATCH: DSK gets a wink from Cristiano as Front Three plays football bingo!\n",
      "Front Three football content creators DSK, Yarns, Juwon and Ali travelled to Saudi Arabia on a quest to meet Al-Nassr star Cristiano Ronaldo!\n",
      "More\n",
      "Queens of football üëë\n",
      "FEATURES\n",
      "NWSL\n",
      "Grading Bethune, Spirit and the 2024 NWSL rookie class\n",
      "INDIVISA grades the 2024 NWSL rookie class after a monumental season for the league\n",
      "AFP\n",
      "J. Lingard\n",
      "Manchester United Women\n",
      "Lingard back at Man Utd?! FC Seoul man trains with cousin George\n",
      "Former Manchester United man Jesse Lingard was back in familiar surroundings as he appeared to train with Gabby George during his off-season break.\n",
      "Getty Images, Sky Sports\n",
      "L. Williamson\n",
      "Arsenal Women\n",
      "Williamson reveals darts nickname and walk-on song for alternate career\n",
      "Arsenal and England defender Leah Williamson reimagined her career as a darts player after trip to 2025 World Championship at Alexandra Palace.\n",
      "GOAL\n",
      "E. Hayes\n",
      "S. Bompastor\n",
      "Hayes says it was 'the right time' to leave Chelsea\n",
      "Former Chelsea boss Emma Hayes has claimed that it was 'the right time' to leave the Blues as she opens up on Sonia Bompastor's perfect start.\n",
      "Getty Images Sport\n",
      "NJ/NY Gotham FC\n",
      "Houston Dash\n",
      "Gotham trade USWNT attacker Ryan to Houston Dash\n",
      "The Bats honored Ryan's request to be traded, with the 25-year-old on the move to Houston\n",
      "More\n",
      "Superstars of the future\n",
      "Getty/GOAL\n",
      "Monaco\n",
      "E. Ben Seghir\n",
      "Why Monaco's teenage 'prince' is on Barca's radar\n",
      "The fleet-footed teenager has been lighting up Stade Louis II in the 2024-25 campaign, and could be in line for a dream move if he can keep it up\n",
      "Getty/GOAL\n",
      "Manchester City\n",
      "Premier League\n",
      "EPL legend's son emerging as City's academy goal machine\n",
      "The tricky winger has scored for the Cityzens at every age group level and all that is left is to make his senior debut alongside his older brother\n",
      "GOAL\n",
      "Chelsea\n",
      "Analysis\n",
      "Why Europe's elite want Chelsea contract rebel Acheampong\n",
      "The versatile defender could be the next jewel of the club's esteemed Cobham academy, but they have a fight on their hands to keep him\n",
      "Getty/GOAL\n",
      "Arsenal\n",
      "Premier League\n",
      "Arsenal's 14-year-old phenom already earning Arteta's trust\n",
      "A midfielder with typical Gunners flair, the schoolboy is set to become the latest talent to come out of the club's Hale End academy\n",
      "More\n",
      "The Chaaaaaampions üé∂\n",
      "Getty Images Sport\n",
      "Manchester United\n",
      "Premier League\n",
      "Man Utd live stream and TV channel broadcast info\n",
      "Everything you need to know about how to watch Man Utd in the Premier League and all major competitions.\n",
      "Getty/GOAL\n",
      "Vinicius Junior\n",
      "K. Mbappe\n",
      "Vinicius warned he could be sold as Mbappe is Real's 'darling'\n",
      "Former Real Madrid scout Manolo Romero has warned Vinicius Junior that Florentino Perez would sell him as he prefers Kylian Mbappe over the Brazilian.\n",
      "Getty/GOAL\n",
      "C. Ronaldo\n",
      "Manchester City\n",
      "Ronaldo gives advice to Man City players amid disastrous form\n",
      "Cristiano Ronaldo had a bit of advice for Manchester City players as he backed Pep Guardiola's side to \"come back\" from their miserable run.\n",
      "Getty/GOAL\n",
      "Arsenal\n",
      "B. Saka\n",
      "Carragher explains what Arsenal need to win Premier League title\n",
      "Jamie Carragher has explained how Mikel Arteta can lead Arsenal to the Premier League title while claiming they depend too much on Bukayo Saka.\n",
      "More\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(goal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messages\n",
    "The API from OpenAI expects to receive messages in a particular structure. Many of the other APIs share this structure:\n",
    "\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the might GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, I'm glad you asked such a challenging question! The answer is 4. But I‚Äôm sure you knew that‚Äîdid you need a calculator for this one?\n"
     ]
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with system and user messages:\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And now let's build useful messages for GPT-4o-mini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build a simple LLM application with chat models and prompt templates | ü¶úÔ∏èüîó LangChain\n",
      "Skip to main content\n",
      "Integrations\n",
      "API Reference\n",
      "More\n",
      "Contributing\n",
      "People\n",
      "Error reference\n",
      "LangSmith\n",
      "LangGraph\n",
      "LangChain Hub\n",
      "LangChain JS/TS\n",
      "v0.3\n",
      "v0.3\n",
      "v0.2\n",
      "v0.1\n",
      "üí¨\n",
      "Search\n",
      "Introduction\n",
      "Tutorials\n",
      "Build a Question Answering application over a Graph Database\n",
      "Tutorials\n",
      "Build a simple LLM application with chat models and prompt templates\n",
      "Build a Chatbot\n",
      "Build a Retrieval Augmented Generation (RAG) App: Part 2\n",
      "Build an Extraction Chain\n",
      "Build an Agent\n",
      "Tagging\n",
      "Build a Retrieval Augmented Generation (RAG) App: Part 1\n",
      "Build a semantic search engine\n",
      "Build a Question/Answering system over SQL data\n",
      "Summarize Text\n",
      "How-to guides\n",
      "How-to guides\n",
      "How to use tools in a chain\n",
      "How to use a vectorstore as a retriever\n",
      "How to add memory to chatbots\n",
      "How to use example selectors\n",
      "How to add a semantic layer over graph database\n",
      "How to invoke runnables in parallel\n",
      "How to stream chat model responses\n",
      "How to add default invocation args to a Runnable\n",
      "How to add retrieval to chatbots\n",
      "How to use few shot examples in chat models\n",
      "How to do tool/function calling\n",
      "How to install LangChain packages\n",
      "How to add examples to the prompt for query analysis\n",
      "How to use few shot examples\n",
      "How to run custom functions\n",
      "How to use output parsers to parse an LLM response into structured format\n",
      "How to handle cases where no queries are generated\n",
      "How to route between sub-chains\n",
      "How to return structured data from a model\n",
      "How to summarize text through parallelization\n",
      "How to summarize text through iterative refinement\n",
      "How to summarize text in a single LLM call\n",
      "How to use toolkits\n",
      "How to add ad-hoc tool calling capability to LLMs and Chat Models\n",
      "Build an Agent with AgentExecutor (Legacy)\n",
      "How to construct knowledge graphs\n",
      "How to partially format prompt templates\n",
      "How to handle multiple queries when doing query analysis\n",
      "How to use built-in tools and toolkits\n",
      "How to pass through arguments from one step to the next\n",
      "How to compose prompts together\n",
      "How to handle multiple retrievers when doing query analysis\n",
      "How to add values to a chain's state\n",
      "How to construct filters for query analysis\n",
      "How to configure runtime chain internals\n",
      "How deal with high cardinality categoricals when doing query analysis\n",
      "Custom Document Loader\n",
      "How to use the MultiQueryRetriever\n",
      "How to add scores to retriever results\n",
      "Caching\n",
      "How to use callbacks in async environments\n",
      "How to attach callbacks to a runnable\n",
      "How to propagate callbacks  constructor\n",
      "How to dispatch custom callback events\n",
      "How to pass callbacks in at runtime\n",
      "How to split by character\n",
      "How to cache chat model responses\n",
      "How to handle rate limits\n",
      "How to init any model in one line\n",
      "How to track token usage in ChatModels\n",
      "How to add tools to chatbots\n",
      "How to split code\n",
      "How to do retrieval with contextual compression\n",
      "How to convert Runnables to Tools\n",
      "How to create custom callback handlers\n",
      "How to create a custom chat model class\n",
      "Custom Embeddings\n",
      "How to create a custom LLM class\n",
      "Custom Retriever\n",
      "How to create tools\n",
      "How to debug your LLM apps\n",
      "How to load CSVs\n",
      "How to load documents from a directory\n",
      "How to load HTML\n",
      "How to load JSON\n",
      "How to load Markdown\n",
      "How to load Microsoft Office files\n",
      "How to load PDFs\n",
      "How to load web pages\n",
      "How to create a dynamic (self-constructing) chain\n",
      "Text embedding models\n",
      "How to combine results from multiple retrievers\n",
      "How to select examples from a LangSmith dataset\n",
      "How to select examples by length\n",
      "How to select examples by maximal marginal relevance (MMR)\n",
      "How to select examples by n-gram overlap\n",
      "How to select examples by similarity\n",
      "How to use reference examples when doing extraction\n",
      "How to handle long text when doing extraction\n",
      "How to use prompting alone (no tool calling) to do extraction\n",
      "How to add fallbacks to a runnable\n",
      "How to filter messages\n",
      "Hybrid Search\n",
      "How to use the LangChain indexing API\n",
      "How to inspect runnables\n",
      "LangChain Expression Language Cheatsheet\n",
      "How to cache LLM responses\n",
      "How to track token usage for LLMs\n",
      "Run models locally\n",
      "How to get log probabilities\n",
      "How to reorder retrieved results to mitigate the \"lost in the middle\" effect\n",
      "How to split Markdown by Headers\n",
      "How to merge consecutive messages of the same type\n",
      "How to add message history\n",
      "How to migrate from legacy LangChain agents to LangGraph\n",
      "How to retrieve using multiple vectors per document\n",
      "How to pass multimodal data directly to models\n",
      "How to use multimodal prompts\n",
      "How to create a custom Output Parser\n",
      "How to use the output-fixing parser\n",
      "How to parse JSON output\n",
      "How to retry when a parsing error occurs\n",
      "How to parse text from message objects\n",
      "How to parse XML output\n",
      "How to parse YAML output\n",
      "How to use the Parent Document Retriever\n",
      "How to use LangChain with different Pydantic versions\n",
      "How to add chat history\n",
      "How to get a RAG application to add citations\n",
      "How to do per-user retrieval\n",
      "How to get your RAG application to return sources\n",
      "How to stream results from your RAG application\n",
      "How to split JSON data\n",
      "How to recursively split text by characters\n",
      "Response metadata\n",
      "How to pass runtime secrets to runnables\n",
      "How to do \"self-querying\" retrieval\n",
      "How to split text based on semantic similarity\n",
      "How to chain runnables\n",
      "How to save and load LangChain objects\n",
      "How to split text by tokens\n",
      "How to split HTML\n",
      "How to do question answering over CSVs\n",
      "How to deal with large databases when doing SQL question-answering\n",
      "How to better prompt when doing SQL question-answering\n",
      "How to do query validation as part of SQL question-answering\n",
      "How to stream runnables\n",
      "How to stream responses from an LLM\n",
      "How to use a time-weighted vector store retriever\n",
      "How to return artifacts from a tool\n",
      "How to use chat models to call tools\n",
      "How to disable parallel tool calling\n",
      "How to force models to call a tool\n",
      "How to access the RunnableConfig from a tool\n",
      "How to pass tool outputs to chat models\n",
      "How to pass run time values to tools\n",
      "How to stream events from a tool\n",
      "How to stream tool calls\n",
      "How to convert tools to OpenAI Functions\n",
      "How to handle tool errors\n",
      "How to use few-shot prompting with tool calling\n",
      "How to add a human-in-the-loop for tools\n",
      "How to bind model-specific tools\n",
      "How to trim messages\n",
      "How to create and query vector stores\n",
      "Conceptual guide\n",
      "Agents\n",
      "Architecture\n",
      "Async programming with langchain\n",
      "Callbacks\n",
      "Chat history\n",
      "Chat models\n",
      "Document loaders\n",
      "Embedding models\n",
      "Evaluation\n",
      "Example selectors\n",
      "Few-shot prompting\n",
      "Conceptual guide\n",
      "Key-value stores\n",
      "LangChain Expression Language (LCEL)\n",
      "Messages\n",
      "Multimodality\n",
      "Output parsers\n",
      "Prompt Templates\n",
      "Retrieval augmented generation (RAG)\n",
      "Retrieval\n",
      "Retrievers\n",
      "Runnable interface\n",
      "Streaming\n",
      "Structured outputs\n",
      "Testing\n",
      "String-in, string-out llms\n",
      "Text splitters\n",
      "Tokens\n",
      "Tool calling\n",
      "Tools\n",
      "Tracing\n",
      "Vector stores\n",
      "Why LangChain?\n",
      "Ecosystem\n",
      "ü¶úüõ†Ô∏è LangSmith\n",
      "ü¶úüï∏Ô∏è LangGraph\n",
      "Versions\n",
      "v0.3\n",
      "v0.2\n",
      "Pydantic compatibility\n",
      "Migrating from v0.0 chains\n",
      "How to migrate from v0.0 chains\n",
      "Migrating from ConstitutionalChain\n",
      "Migrating from ConversationalChain\n",
      "Migrating from ConversationalRetrievalChain\n",
      "Migrating from LLMChain\n",
      "Migrating from LLMMathChain\n",
      "Migrating from LLMRouterChain\n",
      "Migrating from MapReduceDocumentsChain\n",
      "Migrating from MapRerankDocumentsChain\n",
      "Migrating from MultiPromptChain\n",
      "Migrating from RefineDocumentsChain\n",
      "Migrating from RetrievalQA\n",
      "Migrating from StuffDocumentsChain\n",
      "Upgrading to LangGraph memory\n",
      "How to migrate to LangGraph memory\n",
      "How to use BaseChatMessageHistory with LangGraph\n",
      "Migrating off ConversationBufferMemory or ConversationStringBufferMemory\n",
      "Migrating off ConversationBufferWindowMemory or ConversationTokenBufferMemory\n",
      "Migrating off ConversationSummaryMemory or ConversationSummaryBufferMemory\n",
      "A Long-Term Memory Agent\n",
      "Release policy\n",
      "Security Policy\n",
      "Tutorials\n",
      "Build a simple LLM application with chat models and prompt templates\n",
      "On this page\n",
      "Build a simple LLM application with chat models and prompt templates\n",
      "In this quickstart we'll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it's just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!\n",
      "After reading this tutorial, you'll have a high level overview of:\n",
      "Using\n",
      "language models\n",
      "Using\n",
      "prompt templates\n",
      "Debugging and tracing your application using\n",
      "LangSmith\n",
      "Let's dive in!\n",
      "Setup\n",
      "‚Äã\n",
      "Jupyter Notebook\n",
      "‚Äã\n",
      "This and other tutorials are perhaps most conveniently run in a\n",
      "Jupyter notebooks\n",
      ". Going through guides in an interactive environment is a great way to better understand them. See\n",
      "here\n",
      "for instructions on how to install.\n",
      "Installation\n",
      "‚Äã\n",
      "To install LangChain run:\n",
      "Pip\n",
      "Conda\n",
      "pip install langchain\n",
      "conda install langchain -c conda-forge\n",
      "For more details, see our\n",
      "Installation guide\n",
      ".\n",
      "LangSmith\n",
      "‚Äã\n",
      "Many of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\n",
      "As these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\n",
      "The best way to do this is with\n",
      "LangSmith\n",
      ".\n",
      "After you sign up at the link above, make sure to set your environment variables to start logging traces:\n",
      "export LANGCHAIN_TRACING_V2=\"true\"\n",
      "export LANGCHAIN_API_KEY=\"...\"\n",
      "Or, if in a notebook, you can set them with:\n",
      "import\n",
      "getpass\n",
      "import\n",
      "os\n",
      "os\n",
      ".\n",
      "environ\n",
      "[\n",
      "\"LANGCHAIN_TRACING_V2\"\n",
      "]\n",
      "=\n",
      "\"true\"\n",
      "os\n",
      ".\n",
      "environ\n",
      "[\n",
      "\"LANGCHAIN_API_KEY\"\n",
      "]\n",
      "=\n",
      "getpass\n",
      ".\n",
      "getpass\n",
      "(\n",
      ")\n",
      "Using Language Models\n",
      "‚Äã\n",
      "First up, let's learn how to use a language model by itself. LangChain supports many different language models that you can use interchangeably. For details on getting started with a specific model, refer to\n",
      "supported integrations\n",
      ".\n",
      "Select\n",
      "chat model\n",
      ":\n",
      "OpenAI\n",
      "‚ñæ\n",
      "OpenAI\n",
      "Anthropic\n",
      "Azure\n",
      "Google\n",
      "AWS\n",
      "Cohere\n",
      "NVIDIA\n",
      "Fireworks AI\n",
      "Groq\n",
      "Mistral AI\n",
      "Together AI\n",
      "Databricks\n",
      "pip install -qU langchain-openai\n",
      "import\n",
      "getpass\n",
      "import\n",
      "os\n",
      "if\n",
      "not\n",
      "os\n",
      ".\n",
      "environ\n",
      ".\n",
      "get\n",
      "(\n",
      "\"OPENAI_API_KEY\"\n",
      ")\n",
      ":\n",
      "os\n",
      ".\n",
      "environ\n",
      "[\n",
      "\"OPENAI_API_KEY\"\n",
      "]\n",
      "=\n",
      "getpass\n",
      ".\n",
      "getpass\n",
      "(\n",
      "\"Enter API key for OpenAI: \"\n",
      ")\n",
      "from\n",
      "langchain_openai\n",
      "import\n",
      "ChatOpenAI\n",
      "model\n",
      "=\n",
      "ChatOpenAI\n",
      "(\n",
      "model\n",
      "=\n",
      "\"gpt-4o-mini\"\n",
      ")\n",
      "Let's first use the model directly.\n",
      "ChatModels\n",
      "are instances of LangChain\n",
      "Runnables\n",
      ", which means they expose a standard interface for interacting with them. To simply call the model, we can pass in a list of\n",
      "messages\n",
      "to the\n",
      ".invoke\n",
      "method.\n",
      "from\n",
      "langchain_core\n",
      ".\n",
      "messages\n",
      "import\n",
      "HumanMessage\n",
      ",\n",
      "SystemMessage\n",
      "messages\n",
      "=\n",
      "[\n",
      "SystemMessage\n",
      "(\n",
      "\"Translate the following from English into Italian\"\n",
      ")\n",
      ",\n",
      "HumanMessage\n",
      "(\n",
      "\"hi!\"\n",
      ")\n",
      ",\n",
      "]\n",
      "model\n",
      ".\n",
      "invoke\n",
      "(\n",
      "messages\n",
      ")\n",
      "API Reference:\n",
      "HumanMessage\n",
      "|\n",
      "SystemMessage\n",
      "AIMessage(content='Ciao!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 20, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-32654a56-627c-40e1-a141-ad9350bbfd3e-0', usage_metadata={'input_tokens': 20, 'output_tokens': 3, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "tip\n",
      "If we've enabled LangSmith, we can see that this run is logged to LangSmith, and can see the\n",
      "LangSmith trace\n",
      ". The LangSmith trace reports\n",
      "token\n",
      "usage information, latency,\n",
      "standard model parameters\n",
      "(such as temperature), and other information.\n",
      "Note that ChatModels receive\n",
      "message\n",
      "objects as input and generate message objects as output. In addition to text content, message objects convey conversational\n",
      "roles\n",
      "and hold important data, such as\n",
      "tool calls\n",
      "and token usage counts.\n",
      "LangChain also supports chat model inputs via strings or\n",
      "OpenAI format\n",
      ". The following are equivalent:\n",
      "model\n",
      ".\n",
      "invoke\n",
      "(\n",
      "\"Hello\"\n",
      ")\n",
      "model\n",
      ".\n",
      "invoke\n",
      "(\n",
      "[\n",
      "{\n",
      "\"role\"\n",
      ":\n",
      "\"user\"\n",
      ",\n",
      "\"content\"\n",
      ":\n",
      "\"Hello\"\n",
      "}\n",
      "]\n",
      ")\n",
      "model\n",
      ".\n",
      "invoke\n",
      "(\n",
      "[\n",
      "HumanMessage\n",
      "(\n",
      "\"Hello\"\n",
      ")\n",
      "]\n",
      ")\n",
      "Streaming\n",
      "‚Äã\n",
      "Because chat models are\n",
      "Runnables\n",
      ", they expose a standard interface that includes async and streaming modes of invocation. This allows us to stream individual tokens from a chat model:\n",
      "for\n",
      "token\n",
      "in\n",
      "model\n",
      ".\n",
      "stream\n",
      "(\n",
      "messages\n",
      ")\n",
      ":\n",
      "print\n",
      "(\n",
      "token\n",
      ".\n",
      "content\n",
      ",\n",
      "end\n",
      "=\n",
      "\"|\"\n",
      ")\n",
      "|C|iao|!||\n",
      "You can find more details on streaming chat model outputs in\n",
      "this guide\n",
      ".\n",
      "Prompt Templates\n",
      "‚Äã\n",
      "Right now we are passing a list of messages directly into the language model. Where does this list of messages come from? Usually, it is constructed from a combination of user input and application logic. This application logic usually takes the raw user input and transforms it into a list of messages ready to pass to the language model. Common transformations include adding a system message or formatting a template with the user input.\n",
      "Prompt templates\n",
      "are a concept in LangChain designed to assist with this transformation. They take in raw user input and return data (a prompt) that is ready to pass into a language model.\n",
      "Let's create a prompt template here. It will take in two user variables:\n",
      "language\n",
      ": The language to translate text into\n",
      "text\n",
      ": The text to translate\n",
      "from\n",
      "langchain_core\n",
      ".\n",
      "prompts\n",
      "import\n",
      "ChatPromptTemplate\n",
      "system_template\n",
      "=\n",
      "\"Translate the following from English into {language}\"\n",
      "prompt_template\n",
      "=\n",
      "ChatPromptTemplate\n",
      ".\n",
      "from_messages\n",
      "(\n",
      "[\n",
      "(\n",
      "\"system\"\n",
      ",\n",
      "system_template\n",
      ")\n",
      ",\n",
      "(\n",
      "\"user\"\n",
      ",\n",
      "\"{text}\"\n",
      ")\n",
      "]\n",
      ")\n",
      "API Reference:\n",
      "ChatPromptTemplate\n",
      "Note that\n",
      "ChatPromptTemplate\n",
      "supports multiple\n",
      "message roles\n",
      "in a single template. We format the\n",
      "language\n",
      "parameter into the system message, and the user\n",
      "text\n",
      "into a user message.\n",
      "The input to this prompt template is a dictionary. We can play around with this prompt template by itself to see what it does by itself\n",
      "prompt\n",
      "=\n",
      "prompt_template\n",
      ".\n",
      "invoke\n",
      "(\n",
      "{\n",
      "\"language\"\n",
      ":\n",
      "\"Italian\"\n",
      ",\n",
      "\"text\"\n",
      ":\n",
      "\"hi!\"\n",
      "}\n",
      ")\n",
      "prompt\n",
      "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])\n",
      "We can see that it returns a\n",
      "ChatPromptValue\n",
      "that consists of two messages. If we want to access the messages directly we do:\n",
      "prompt\n",
      ".\n",
      "to_messages\n",
      "(\n",
      ")\n",
      "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
      "HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]\n",
      "Finally, we can invoke the chat model on the formatted prompt:\n",
      "response\n",
      "=\n",
      "model\n",
      ".\n",
      "invoke\n",
      "(\n",
      "prompt\n",
      ")\n",
      "print\n",
      "(\n",
      "response\n",
      ".\n",
      "content\n",
      ")\n",
      "Ciao!\n",
      "tip\n",
      "Message\n",
      "content\n",
      "can contain both text and\n",
      "content blocks\n",
      "with additional structure. See\n",
      "this guide\n",
      "for more information.\n",
      "If we take a look at the\n",
      "LangSmith trace\n",
      ", we can see exactly what prompt the chat model receives, along with\n",
      "token\n",
      "usage information, latency,\n",
      "standard model parameters\n",
      "(such as temperature), and other information.\n",
      "Conclusion\n",
      "‚Äã\n",
      "That's it! In this tutorial you've learned how to create your first simple LLM application. You've learned how to work with language models, how to create a prompt template, and how to get great observability into applications you create with LangSmith.\n",
      "This just scratches the surface of what you will want to learn to become a proficient AI Engineer. Luckily - we've got a lot of other resources!\n",
      "For further reading on the core concepts of LangChain, we've got detailed\n",
      "Conceptual Guides\n",
      ".\n",
      "If you have more specific questions on these concepts, check out the following sections of the how-to guides:\n",
      "Chat models\n",
      "Prompt templates\n",
      "And the LangSmith docs:\n",
      "LangSmith\n",
      "Edit this page\n",
      "Was this page helpful?\n",
      "Previous\n",
      "Tutorials\n",
      "Next\n",
      "Build a Chatbot\n",
      "Setup\n",
      "Jupyter Notebook\n",
      "Installation\n",
      "LangSmith\n",
      "Using Language Models\n",
      "Streaming\n",
      "Prompt Templates\n",
      "Conclusion\n",
      "Community\n",
      "Twitter\n",
      "GitHub\n",
      "Organization\n",
      "Python\n",
      "JS/TS\n",
      "More\n",
      "Homepage\n",
      "Blog\n",
      "YouTube\n",
      "Copyright ¬© 2024 LangChain, Inc.\n"
     ]
    }
   ],
   "source": [
    "# Try few website for exercises\n",
    "\n",
    "langchain=Website(\"https://python.langchain.com/docs/tutorials/llm_chain/\")\n",
    "print(langchain.title)\n",
    "print(langchain.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Build a simple LLM application with chat models and prompt templates | ü¶úÔ∏èüîó LangChain\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nSkip to main content\\nIntegrations\\nAPI Reference\\nMore\\nContributing\\nPeople\\nError reference\\nLangSmith\\nLangGraph\\nLangChain Hub\\nLangChain JS/TS\\nv0.3\\nv0.3\\nv0.2\\nv0.1\\nüí¨\\nSearch\\nIntroduction\\nTutorials\\nBuild a Question Answering application over a Graph Database\\nTutorials\\nBuild a simple LLM application with chat models and prompt templates\\nBuild a Chatbot\\nBuild a Retrieval Augmented Generation (RAG) App: Part 2\\nBuild an Extraction Chain\\nBuild an Agent\\nTagging\\nBuild a Retrieval Augmented Generation (RAG) App: Part 1\\nBuild a semantic search engine\\nBuild a Question/Answering system over SQL data\\nSummarize Text\\nHow-to guides\\nHow-to guides\\nHow to use tools in a chain\\nHow to use a vectorstore as a retriever\\nHow to add memory to chatbots\\nHow to use example selectors\\nHow to add a semantic layer over graph database\\nHow to invoke runnables in parallel\\nHow to stream chat model responses\\nHow to add default invocation args to a Runnable\\nHow to add retrieval to chatbots\\nHow to use few shot examples in chat models\\nHow to do tool/function calling\\nHow to install LangChain packages\\nHow to add examples to the prompt for query analysis\\nHow to use few shot examples\\nHow to run custom functions\\nHow to use output parsers to parse an LLM response into structured format\\nHow to handle cases where no queries are generated\\nHow to route between sub-chains\\nHow to return structured data from a model\\nHow to summarize text through parallelization\\nHow to summarize text through iterative refinement\\nHow to summarize text in a single LLM call\\nHow to use toolkits\\nHow to add ad-hoc tool calling capability to LLMs and Chat Models\\nBuild an Agent with AgentExecutor (Legacy)\\nHow to construct knowledge graphs\\nHow to partially format prompt templates\\nHow to handle multiple queries when doing query analysis\\nHow to use built-in tools and toolkits\\nHow to pass through arguments from one step to the next\\nHow to compose prompts together\\nHow to handle multiple retrievers when doing query analysis\\nHow to add values to a chain\\'s state\\nHow to construct filters for query analysis\\nHow to configure runtime chain internals\\nHow deal with high cardinality categoricals when doing query analysis\\nCustom Document Loader\\nHow to use the MultiQueryRetriever\\nHow to add scores to retriever results\\nCaching\\nHow to use callbacks in async environments\\nHow to attach callbacks to a runnable\\nHow to propagate callbacks  constructor\\nHow to dispatch custom callback events\\nHow to pass callbacks in at runtime\\nHow to split by character\\nHow to cache chat model responses\\nHow to handle rate limits\\nHow to init any model in one line\\nHow to track token usage in ChatModels\\nHow to add tools to chatbots\\nHow to split code\\nHow to do retrieval with contextual compression\\nHow to convert Runnables to Tools\\nHow to create custom callback handlers\\nHow to create a custom chat model class\\nCustom Embeddings\\nHow to create a custom LLM class\\nCustom Retriever\\nHow to create tools\\nHow to debug your LLM apps\\nHow to load CSVs\\nHow to load documents from a directory\\nHow to load HTML\\nHow to load JSON\\nHow to load Markdown\\nHow to load Microsoft Office files\\nHow to load PDFs\\nHow to load web pages\\nHow to create a dynamic (self-constructing) chain\\nText embedding models\\nHow to combine results from multiple retrievers\\nHow to select examples from a LangSmith dataset\\nHow to select examples by length\\nHow to select examples by maximal marginal relevance (MMR)\\nHow to select examples by n-gram overlap\\nHow to select examples by similarity\\nHow to use reference examples when doing extraction\\nHow to handle long text when doing extraction\\nHow to use prompting alone (no tool calling) to do extraction\\nHow to add fallbacks to a runnable\\nHow to filter messages\\nHybrid Search\\nHow to use the LangChain indexing API\\nHow to inspect runnables\\nLangChain Expression Language Cheatsheet\\nHow to cache LLM responses\\nHow to track token usage for LLMs\\nRun models locally\\nHow to get log probabilities\\nHow to reorder retrieved results to mitigate the \"lost in the middle\" effect\\nHow to split Markdown by Headers\\nHow to merge consecutive messages of the same type\\nHow to add message history\\nHow to migrate from legacy LangChain agents to LangGraph\\nHow to retrieve using multiple vectors per document\\nHow to pass multimodal data directly to models\\nHow to use multimodal prompts\\nHow to create a custom Output Parser\\nHow to use the output-fixing parser\\nHow to parse JSON output\\nHow to retry when a parsing error occurs\\nHow to parse text from message objects\\nHow to parse XML output\\nHow to parse YAML output\\nHow to use the Parent Document Retriever\\nHow to use LangChain with different Pydantic versions\\nHow to add chat history\\nHow to get a RAG application to add citations\\nHow to do per-user retrieval\\nHow to get your RAG application to return sources\\nHow to stream results from your RAG application\\nHow to split JSON data\\nHow to recursively split text by characters\\nResponse metadata\\nHow to pass runtime secrets to runnables\\nHow to do \"self-querying\" retrieval\\nHow to split text based on semantic similarity\\nHow to chain runnables\\nHow to save and load LangChain objects\\nHow to split text by tokens\\nHow to split HTML\\nHow to do question answering over CSVs\\nHow to deal with large databases when doing SQL question-answering\\nHow to better prompt when doing SQL question-answering\\nHow to do query validation as part of SQL question-answering\\nHow to stream runnables\\nHow to stream responses from an LLM\\nHow to use a time-weighted vector store retriever\\nHow to return artifacts from a tool\\nHow to use chat models to call tools\\nHow to disable parallel tool calling\\nHow to force models to call a tool\\nHow to access the RunnableConfig from a tool\\nHow to pass tool outputs to chat models\\nHow to pass run time values to tools\\nHow to stream events from a tool\\nHow to stream tool calls\\nHow to convert tools to OpenAI Functions\\nHow to handle tool errors\\nHow to use few-shot prompting with tool calling\\nHow to add a human-in-the-loop for tools\\nHow to bind model-specific tools\\nHow to trim messages\\nHow to create and query vector stores\\nConceptual guide\\nAgents\\nArchitecture\\nAsync programming with langchain\\nCallbacks\\nChat history\\nChat models\\nDocument loaders\\nEmbedding models\\nEvaluation\\nExample selectors\\nFew-shot prompting\\nConceptual guide\\nKey-value stores\\nLangChain Expression Language (LCEL)\\nMessages\\nMultimodality\\nOutput parsers\\nPrompt Templates\\nRetrieval augmented generation (RAG)\\nRetrieval\\nRetrievers\\nRunnable interface\\nStreaming\\nStructured outputs\\nTesting\\nString-in, string-out llms\\nText splitters\\nTokens\\nTool calling\\nTools\\nTracing\\nVector stores\\nWhy LangChain?\\nEcosystem\\nü¶úüõ†Ô∏è LangSmith\\nü¶úüï∏Ô∏è LangGraph\\nVersions\\nv0.3\\nv0.2\\nPydantic compatibility\\nMigrating from v0.0 chains\\nHow to migrate from v0.0 chains\\nMigrating from ConstitutionalChain\\nMigrating from ConversationalChain\\nMigrating from ConversationalRetrievalChain\\nMigrating from LLMChain\\nMigrating from LLMMathChain\\nMigrating from LLMRouterChain\\nMigrating from MapReduceDocumentsChain\\nMigrating from MapRerankDocumentsChain\\nMigrating from MultiPromptChain\\nMigrating from RefineDocumentsChain\\nMigrating from RetrievalQA\\nMigrating from StuffDocumentsChain\\nUpgrading to LangGraph memory\\nHow to migrate to LangGraph memory\\nHow to use BaseChatMessageHistory with LangGraph\\nMigrating off ConversationBufferMemory or ConversationStringBufferMemory\\nMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemory\\nMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemory\\nA Long-Term Memory Agent\\nRelease policy\\nSecurity Policy\\nTutorials\\nBuild a simple LLM application with chat models and prompt templates\\nOn this page\\nBuild a simple LLM application with chat models and prompt templates\\nIn this quickstart we\\'ll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it\\'s just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!\\nAfter reading this tutorial, you\\'ll have a high level overview of:\\nUsing\\nlanguage models\\nUsing\\nprompt templates\\nDebugging and tracing your application using\\nLangSmith\\nLet\\'s dive in!\\nSetup\\n\\u200b\\nJupyter Notebook\\n\\u200b\\nThis and other tutorials are perhaps most conveniently run in a\\nJupyter notebooks\\n. Going through guides in an interactive environment is a great way to better understand them. See\\nhere\\nfor instructions on how to install.\\nInstallation\\n\\u200b\\nTo install LangChain run:\\nPip\\nConda\\npip install langchain\\nconda install langchain -c conda-forge\\nFor more details, see our\\nInstallation guide\\n.\\nLangSmith\\n\\u200b\\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\\nAs these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\\nThe best way to do this is with\\nLangSmith\\n.\\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\\nexport LANGCHAIN_TRACING_V2=\"true\"\\nexport LANGCHAIN_API_KEY=\"...\"\\nOr, if in a notebook, you can set them with:\\nimport\\ngetpass\\nimport\\nos\\nos\\n.\\nenviron\\n[\\n\"LANGCHAIN_TRACING_V2\"\\n]\\n=\\n\"true\"\\nos\\n.\\nenviron\\n[\\n\"LANGCHAIN_API_KEY\"\\n]\\n=\\ngetpass\\n.\\ngetpass\\n(\\n)\\nUsing Language Models\\n\\u200b\\nFirst up, let\\'s learn how to use a language model by itself. LangChain supports many different language models that you can use interchangeably. For details on getting started with a specific model, refer to\\nsupported integrations\\n.\\nSelect\\nchat model\\n:\\nOpenAI\\n‚ñæ\\nOpenAI\\nAnthropic\\nAzure\\nGoogle\\nAWS\\nCohere\\nNVIDIA\\nFireworks AI\\nGroq\\nMistral AI\\nTogether AI\\nDatabricks\\npip install -qU langchain-openai\\nimport\\ngetpass\\nimport\\nos\\nif\\nnot\\nos\\n.\\nenviron\\n.\\nget\\n(\\n\"OPENAI_API_KEY\"\\n)\\n:\\nos\\n.\\nenviron\\n[\\n\"OPENAI_API_KEY\"\\n]\\n=\\ngetpass\\n.\\ngetpass\\n(\\n\"Enter API key for OpenAI: \"\\n)\\nfrom\\nlangchain_openai\\nimport\\nChatOpenAI\\nmodel\\n=\\nChatOpenAI\\n(\\nmodel\\n=\\n\"gpt-4o-mini\"\\n)\\nLet\\'s first use the model directly.\\nChatModels\\nare instances of LangChain\\nRunnables\\n, which means they expose a standard interface for interacting with them. To simply call the model, we can pass in a list of\\nmessages\\nto the\\n.invoke\\nmethod.\\nfrom\\nlangchain_core\\n.\\nmessages\\nimport\\nHumanMessage\\n,\\nSystemMessage\\nmessages\\n=\\n[\\nSystemMessage\\n(\\n\"Translate the following from English into Italian\"\\n)\\n,\\nHumanMessage\\n(\\n\"hi!\"\\n)\\n,\\n]\\nmodel\\n.\\ninvoke\\n(\\nmessages\\n)\\nAPI Reference:\\nHumanMessage\\n|\\nSystemMessage\\nAIMessage(content=\\'Ciao!\\', additional_kwargs={\\'refusal\\': None}, response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 3, \\'prompt_tokens\\': 20, \\'total_tokens\\': 23, \\'completion_tokens_details\\': {\\'accepted_prediction_tokens\\': 0, \\'audio_tokens\\': 0, \\'reasoning_tokens\\': 0, \\'rejected_prediction_tokens\\': 0}, \\'prompt_tokens_details\\': {\\'audio_tokens\\': 0, \\'cached_tokens\\': 0}}, \\'model_name\\': \\'gpt-4o-mini-2024-07-18\\', \\'system_fingerprint\\': \\'fp_0705bf87c0\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-32654a56-627c-40e1-a141-ad9350bbfd3e-0\\', usage_metadata={\\'input_tokens\\': 20, \\'output_tokens\\': 3, \\'total_tokens\\': 23, \\'input_token_details\\': {\\'audio\\': 0, \\'cache_read\\': 0}, \\'output_token_details\\': {\\'audio\\': 0, \\'reasoning\\': 0}})\\ntip\\nIf we\\'ve enabled LangSmith, we can see that this run is logged to LangSmith, and can see the\\nLangSmith trace\\n. The LangSmith trace reports\\ntoken\\nusage information, latency,\\nstandard model parameters\\n(such as temperature), and other information.\\nNote that ChatModels receive\\nmessage\\nobjects as input and generate message objects as output. In addition to text content, message objects convey conversational\\nroles\\nand hold important data, such as\\ntool calls\\nand token usage counts.\\nLangChain also supports chat model inputs via strings or\\nOpenAI format\\n. The following are equivalent:\\nmodel\\n.\\ninvoke\\n(\\n\"Hello\"\\n)\\nmodel\\n.\\ninvoke\\n(\\n[\\n{\\n\"role\"\\n:\\n\"user\"\\n,\\n\"content\"\\n:\\n\"Hello\"\\n}\\n]\\n)\\nmodel\\n.\\ninvoke\\n(\\n[\\nHumanMessage\\n(\\n\"Hello\"\\n)\\n]\\n)\\nStreaming\\n\\u200b\\nBecause chat models are\\nRunnables\\n, they expose a standard interface that includes async and streaming modes of invocation. This allows us to stream individual tokens from a chat model:\\nfor\\ntoken\\nin\\nmodel\\n.\\nstream\\n(\\nmessages\\n)\\n:\\nprint\\n(\\ntoken\\n.\\ncontent\\n,\\nend\\n=\\n\"|\"\\n)\\n|C|iao|!||\\nYou can find more details on streaming chat model outputs in\\nthis guide\\n.\\nPrompt Templates\\n\\u200b\\nRight now we are passing a list of messages directly into the language model. Where does this list of messages come from? Usually, it is constructed from a combination of user input and application logic. This application logic usually takes the raw user input and transforms it into a list of messages ready to pass to the language model. Common transformations include adding a system message or formatting a template with the user input.\\nPrompt templates\\nare a concept in LangChain designed to assist with this transformation. They take in raw user input and return data (a prompt) that is ready to pass into a language model.\\nLet\\'s create a prompt template here. It will take in two user variables:\\nlanguage\\n: The language to translate text into\\ntext\\n: The text to translate\\nfrom\\nlangchain_core\\n.\\nprompts\\nimport\\nChatPromptTemplate\\nsystem_template\\n=\\n\"Translate the following from English into {language}\"\\nprompt_template\\n=\\nChatPromptTemplate\\n.\\nfrom_messages\\n(\\n[\\n(\\n\"system\"\\n,\\nsystem_template\\n)\\n,\\n(\\n\"user\"\\n,\\n\"{text}\"\\n)\\n]\\n)\\nAPI Reference:\\nChatPromptTemplate\\nNote that\\nChatPromptTemplate\\nsupports multiple\\nmessage roles\\nin a single template. We format the\\nlanguage\\nparameter into the system message, and the user\\ntext\\ninto a user message.\\nThe input to this prompt template is a dictionary. We can play around with this prompt template by itself to see what it does by itself\\nprompt\\n=\\nprompt_template\\n.\\ninvoke\\n(\\n{\\n\"language\"\\n:\\n\"Italian\"\\n,\\n\"text\"\\n:\\n\"hi!\"\\n}\\n)\\nprompt\\nChatPromptValue(messages=[SystemMessage(content=\\'Translate the following from English into Italian\\', additional_kwargs={}, response_metadata={}), HumanMessage(content=\\'hi!\\', additional_kwargs={}, response_metadata={})])\\nWe can see that it returns a\\nChatPromptValue\\nthat consists of two messages. If we want to access the messages directly we do:\\nprompt\\n.\\nto_messages\\n(\\n)\\n[SystemMessage(content=\\'Translate the following from English into Italian\\', additional_kwargs={}, response_metadata={}),\\nHumanMessage(content=\\'hi!\\', additional_kwargs={}, response_metadata={})]\\nFinally, we can invoke the chat model on the formatted prompt:\\nresponse\\n=\\nmodel\\n.\\ninvoke\\n(\\nprompt\\n)\\nprint\\n(\\nresponse\\n.\\ncontent\\n)\\nCiao!\\ntip\\nMessage\\ncontent\\ncan contain both text and\\ncontent blocks\\nwith additional structure. See\\nthis guide\\nfor more information.\\nIf we take a look at the\\nLangSmith trace\\n, we can see exactly what prompt the chat model receives, along with\\ntoken\\nusage information, latency,\\nstandard model parameters\\n(such as temperature), and other information.\\nConclusion\\n\\u200b\\nThat\\'s it! In this tutorial you\\'ve learned how to create your first simple LLM application. You\\'ve learned how to work with language models, how to create a prompt template, and how to get great observability into applications you create with LangSmith.\\nThis just scratches the surface of what you will want to learn to become a proficient AI Engineer. Luckily - we\\'ve got a lot of other resources!\\nFor further reading on the core concepts of LangChain, we\\'ve got detailed\\nConceptual Guides\\n.\\nIf you have more specific questions on these concepts, check out the following sections of the how-to guides:\\nChat models\\nPrompt templates\\nAnd the LangSmith docs:\\nLangSmith\\nEdit this page\\nWas this page helpful?\\nPrevious\\nTutorials\\nNext\\nBuild a Chatbot\\nSetup\\nJupyter Notebook\\nInstallation\\nLangSmith\\nUsing Language Models\\nStreaming\\nPrompt Templates\\nConclusion\\nCommunity\\nTwitter\\nGitHub\\nOrganization\\nPython\\nJS/TS\\nMore\\nHomepage\\nBlog\\nYouTube\\nCopyright ¬© 2024 LangChain, Inc.'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_for(langchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap up and Brint it Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Summary of \"Build a simple LLM application with chat models and prompt templates | LangChain\"\\n\\nThis tutorial provides a step-by-step guide on how to create a simple Language Model (LLM) application using LangChain. The application will translate text from English to another language utilizing chat models and prompt templates.\\n\\n## Key Components Covered:\\n- **Language Models**: An overview of how to utilize various language models within the LangChain framework.\\n- **Prompt Templates**: The tutorial explains how to create prompt templates that take user input and format it for a model.\\n- **Debugging with LangSmith**: Users are introduced to LangSmith, a tool for tracing and debugging LLM applications, which is valuable as applications grow in complexity.\\n\\n## Installation:\\nInstructions are provided for setting up LangChain via `pip` or `conda`. Users are encouraged to utilize Jupyter Notebook for an interactive learning experience.\\n\\n## Example Implementation:\\nAn example is given where a chat model is employed to translate text. It details the initialization of the model, how to format input messages, and how to invoke the translation function.\\n\\n## Conclusion:\\nBy the end of the tutorial, users should have a foundational understanding of building an LLM application, including the use of chat models, prompt templates, and logging with LangSmith for improved observability.\\n\\nFurther resources and conceptual guides are suggested for those looking to deepen their knowledge in AI engineering.\\n\\n--- \\n\\nFeel free to explore the tutorial for more detailed instructions and practical examples!'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://python.langchain.com/docs/tutorials/llm_chain/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of the Website: Build a simple LLM application with chat models and prompt templates | ü¶úÔ∏èüîó LangChain\n",
       "\n",
       "This website provides a tutorial on building a simple LLM (Large Language Model) application using LangChain, specifically for translating text from English into another language. \n",
       "\n",
       "## Key Points:\n",
       "\n",
       "- **Getting Started**: \n",
       "  - The application is designed for beginners and demonstrates the use of a single LLM call combined with prompting techniques.\n",
       "  \n",
       "- **Tutorial Highlights**:\n",
       "  - **Setup and Installation**: Instructions for running the tutorial in Jupyter Notebook, with installation commands for Python packages.\n",
       "  - **Using Language Models**: Guides on utilizing various language models, including OpenAI.\n",
       "  - **Prompt Templates**: Explanation of how to use prompt templates to transform user input into structured formats for LLM processing.\n",
       "  - **LangSmith Integration**: Emphasizes the importance of debugging and tracing applications as complexity increases, using LangSmith for logging and tracing runs.\n",
       "\n",
       "- **Conclusion**: The tutorial outlines the foundational skills necessary for creating LLM applications and encourages further exploration of LangChain's resources for deeper knowledge on related concepts.\n",
       "\n",
       "This beginner-friendly guide serves as a stepping stone for anyone looking to learn about LLM applications and how to implement them using LangChain's functionalities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://python.langchain.com/docs/tutorials/llm_chain/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try more Websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# DeepLearning.AI Summary\n",
       "\n",
       "DeepLearning.AI is an educational platform designed to help individuals start or advance their careers in artificial intelligence (AI). It offers a variety of online courses and specializations focused on machine learning and AI applications in the real world, facilitated by AI pioneer Andrew Ng.\n",
       "\n",
       "## Key Features:\n",
       "\n",
       "- **Courses and Specializations**: A range of courses to build foundational skills in AI and machine learning.\n",
       "- **AI Newsletter**: The Batch provides weekly updates on the latest in AI, including notable stories and advancements in the field.\n",
       "- **Free Resources**: Users can access materials like \"Machine Learning Yearning\" and comprehensive guides on natural language processing to enhance their learning.\n",
       "- **Community Engagement**: Offers opportunities to participate in events and forums to connect with other learners and experts in AI.\n",
       "\n",
       "## Recent News & Insights from The Batch:\n",
       "- **Dec 25, 2024**: Highlights of top AI stories for the year, including advancements in agents, pricing trends, and the emergence of video in AI.\n",
       "- **Dec 18, 2024**: Discussion on significant technological advancements, noting the rapid pace of AI application development.\n",
       "- **Dec 11, 2024**: Acknowledgment of achievements by former students in the AI research community, as well as developments in AI product management and competitive performance metrics.\n",
       "\n",
       "Overall, DeepLearning.AI aims to empower over seven million learners in harnessing AI's capabilities through robust educational resources and community support."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://deeplearning.ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# CoinMarketCap Overview\n",
       "\n",
       "CoinMarketCap is a comprehensive platform that provides real-time data on cryptocurrency prices, charts, and market capitalizations. Established in 2013, the site aims to be the premier resource for cryptocurrency market data, focusing on accuracy and timeliness.\n",
       "\n",
       "## Key Features:\n",
       "- **Market Data**: Displays current cryptocurrency prices, historical snapshots, and rankings. \n",
       "- **Market Overview**: Details include the total cryptocurrency market cap of approximately **$3.26 trillion**, a 24-hour trading volume of **$107.46 billion**, and a Bitcoin dominance rate of **56.7%**.\n",
       "- ** charts and APIs**: Offers live and historical crypto charts for free; has APIs used by major exchanges.\n",
       "- **Diverse Listings**: Tracks over **2.4 million** cryptocurrencies and **773** exchanges, with filters for trending assets and categories.\n",
       "\n",
       "## Cryptocurrency Insights:\n",
       "- The site also provides educational resources such as articles, an academy, and a glossary for newcomers to understand concepts like altcoins, smart contracts, and stablecoins.\n",
       "  \n",
       "## Recent Developments:\n",
       "- **ETF Approval**: Alludes to the recent approval of multiple Bitcoin ETFs by the SEC, which will allow broader retail investor access in the U.S.\n",
       "  \n",
       "## User Engagement:\n",
       "- Encourages community interaction through features such as community votes, leaderboards, and sentiment analysis, promoting active participation from users.\n",
       "\n",
       "CoinMarketCap continues to evolve, providing users with essential resources for navigating the rapidly changing cryptocurrency landscape."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://coinmarketcap.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Anthropic Website Summary\n",
       "\n",
       "## Overview\n",
       "Anthropic is an AI safety and research company based in San Francisco. The organization focuses on developing reliable and beneficial AI systems through an interdisciplinary approach that combines expertise in machine learning, physics, policy, and product development.\n",
       "\n",
       "## AI Products\n",
       "- **Claude**: Anthropic's latest AI model, Claude 3.5 Sonnet, is highlighted as their most intelligent AI variant. The website offers users the ability to interact with Claude and provides an API for developers to create AI-powered applications and experiences.\n",
       "\n",
       "## Announcements\n",
       "- **October 22, 2024**: Introduction of new AI models, Claude 3.5 Sonnet and Claude 3.5 Haiku, alongside a new feature for computer use.\n",
       "- **September 4, 2024**: Launch of Claude for Enterprise.\n",
       "- **Previous Announcements**:\n",
       "  - **December 15, 2022**: Research on \"Constitutional AI: Harmlessness from AI Feedback.\"\n",
       "  - **March 8, 2023**: Release on \"Core Views on AI Safety: When, Why, What, and How.\"\n",
       "\n",
       "## Employment\n",
       "The company has open roles and emphasizes collaboration within their diverse team to advance AI safety and research initiatives."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
